{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Breast cancer incidence rate prediction</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I- Preprocessing: data importation and imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pylab\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('set_prov.csv', sep=';', decimal=',')\n",
    "# Remove two columns: 'pays' and 'identifiants de pays' \n",
    "df2 = df.drop(['id','pays'],  axis='columns')\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "imp_mean = KNNImputer(n_neighbors = 9)\n",
    "imp_mean.fit(df2)\n",
    "imputed_df1 = imp_mean.transform(df2)\n",
    "imputed_df1 = pd.DataFrame(imputed_df1, columns=df2.columns)\n",
    "imputed_df = imputed_df1.drop(['crude'],  axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II- Breast cancer incidence rates over countries in 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantiles = df[\"crude\"].quantile([0.25, 0.50, 0.75])\n",
    "Q1 = df[df[\"crude\"] < quantiles[0.25]][\"pays\"].tolist()\n",
    "Q2 = df[(df[\"crude\"] >= quantiles[0.25]) & (df[\"crude\"] < quantiles[0.50])][\"pays\"].tolist()\n",
    "Q3 = df[(df[\"crude\"] >= quantiles[0.50]) & (df[\"crude\"] < quantiles[0.75])][\"pays\"].tolist()\n",
    "Q4 = df[df[\"crude\"] >= quantiles[0.75]][\"pays\"].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Countries with low incidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Countries with medium incidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Q2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Countries with high incidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Countries with very high incidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III- Correlation between breast cancer incidence rates and the studied factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr, shapiro, probplot\n",
    "\n",
    "Risk_factors_list = imputed_df.columns.tolist()\n",
    "data2 = imputed_df1['crude']\n",
    "\n",
    "spearman_corr = []\n",
    "spearman_pvalue = []\n",
    "normality_results = []\n",
    "\n",
    "# Calculate number of rows needed\n",
    "n_factors = len(Risk_factors_list)\n",
    "n_cols = 4  # 2 histograms and 2 Q-Q plots per row\n",
    "n_rows = (n_factors + (n_cols // 2) - 1) // (n_cols // 2)\n",
    "\n",
    "# Create a figure to store all distributions\n",
    "data_distribution = plt.figure(figsize=(20, n_rows * 5))\n",
    "\n",
    "# Visualize data and evaluate normality\n",
    "for i, s in enumerate(Risk_factors_list):\n",
    "    data1 = imputed_df[s]\n",
    "    \n",
    "    # Normality check\n",
    "    shapiro_test = shapiro(data1)\n",
    "    normality_results.append({\n",
    "        'Factor': s,\n",
    "        'Statistic': shapiro_test.statistic,\n",
    "        'P-value': shapiro_test.pvalue,\n",
    "        'Normal Distribution': shapiro_test.pvalue > 0.05\n",
    "    })\n",
    "    \n",
    "    # Add histogram\n",
    "    plt.subplot(n_rows, n_cols, i * 2 + 1)\n",
    "    sns.histplot(data1, kde=True)\n",
    "    plt.title(f'Histogram of {s}')\n",
    "    \n",
    "    # Add Q-Q plot\n",
    "    plt.subplot(n_rows, n_cols, i * 2 + 2)\n",
    "    probplot(data1, dist=\"norm\", plot=plt)\n",
    "    plt.title(f'Q-Q Plot of {s}')\n",
    "\n",
    "    # Calculate Spearman's rank correlation\n",
    "    rho, p = spearmanr(data1, data2)\n",
    "    spearman_corr.append(np.around(rho, 2))\n",
    "    spearman_pvalue.append(p)\n",
    "\n",
    "# Create DataFrames for normality and Spearman results\n",
    "normality_results_df = pd.DataFrame(normality_results)\n",
    "spearman_result_table = pd.DataFrame({\n",
    "    \"Correlation\": spearman_corr,\n",
    "    \"P-value\": spearman_pvalue,\n",
    "}, index=Risk_factors_list)\n",
    "\n",
    "# Save the figure\n",
    "data_distribution.savefig('data_distribution.png', bbox_inches='tight')\n",
    "\n",
    "# Print the results\n",
    "print(\"Shapiro-Wilk Test Results:\")\n",
    "print(normality_results_df)\n",
    "\n",
    "print(\"\\nSpearman Correlation Results:\")\n",
    "spearman_result_table.sort_values(by='Correlation', ascending=False, inplace=True)\n",
    "print(spearman_result_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV- Breast Cancer Incidence Rate Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spliting data to X and Y and standardizing X set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X = imputed_df1.drop(['crude'], axis = 1)\n",
    "Y = imputed_df1.crude\n",
    "X = StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spliting X and Y to train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state = 2276)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "from sklearn.metrics import mean_absolute_error as MAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Forward Feature Selection for each regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.feature_selection import SequentialFeatureSelector as sfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_for_each_num_of_features = []\n",
    "\n",
    "regressors = [SVR(kernel = 'linear'),\n",
    "              LinearRegression(),\n",
    "              RandomForestRegressor(),\n",
    "              XGBRegressor(),\n",
    "              LGBMRegressor(),\n",
    "              CatBoostRegressor(silent = True)]\n",
    "reg_names = ['SVR','Linear Reg','Random Forest','XGBoost', 'Light GBM', 'CatBoost']\n",
    "for regressor, r_name in zip(regressors, reg_names):\n",
    "    result_for_each_num_of_features.clear()\n",
    "    print('='*20,end=\"\")\n",
    "    print('\\t', r_name, '\\t', end=\"\")\n",
    "    print('='*20)\n",
    "    \n",
    "    for i in range(1,16):\n",
    "        # Testing FFS        \n",
    "        # Build step forward feature selection\n",
    "        sfs1 = sfs(regressor,\n",
    "                   k_features = i, \n",
    "                   forward = True,\n",
    "                   floating = False,\n",
    "                   verbose = 2,\n",
    "                   scoring = 'r2',\n",
    "                   cv = 5,\n",
    "                   )\n",
    "        # Perform SFFS\n",
    "        sfs1 = sfs1.fit(X_train, y_train)\n",
    "        # Which features?\n",
    "        feat_cols = list(sfs1.k_feature_idx_)\n",
    "        # Build full model with selected features\n",
    "        regressor.fit(X_train[:, feat_cols], y_train)\n",
    "        y_test_pred = regressor.predict(X_test[:, feat_cols])\n",
    "        result_for_each_num_of_features.append(r2_score(y_test, y_test_pred))\n",
    "    print('-'*90)\n",
    "    print('='*20,end=\"\")\n",
    "    print('\\t', r_name, '\\t', end=\"\")\n",
    "    print('='*20)\n",
    "    for result in result_for_each_num_of_features:\n",
    "        print(\"%.3f\" % result)  \n",
    "    print('-'*90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "randomlist = []\n",
    "for i in range(0,50):\n",
    "    n = random.randint(2000,2500)\n",
    "    randomlist.append(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state = 2276)\n",
    "feat_cols = []\n",
    "# Testing FFS\n",
    "# Build Regressor to use in feature selection\n",
    "reg = SVR(kernel = 'linear')\n",
    "# Build step forward feature selection\n",
    "sfs1 = sfs(reg,\n",
    "           k_features = 8, # choisir après constatation\n",
    "           forward = True,\n",
    "           floating = False,\n",
    "           verbose = 2,\n",
    "           scoring = 'r2',\n",
    "           cv = 5,)\n",
    "\n",
    "# Perform SFFS\n",
    "sfs1 = sfs1.fit(X_train, y_train)\n",
    "# Which features?\n",
    "feat_cols = list(sfs1.k_feature_idx_)\n",
    "print(feat_cols)\n",
    "# Build full model with selected features\n",
    "reg.fit(X_train[:, feat_cols], y_train)\n",
    "y_test_pred = reg.predict(X_test[:, feat_cols])\n",
    "print('Testing R² on selected features: %.3f' % r2_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_squ = []\n",
    "MAEe = []\n",
    "RMSEe = []\n",
    "\n",
    "regressor = SVR(kernel = 'linear')\n",
    "for i in randomlist:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state = i)\n",
    "    regressor.fit(X_train[:, feat_cols], y_train)\n",
    "    preds = regressor.predict(X_test[:, feat_cols])\n",
    "    r_squ.append(r2_score(y_test, preds))\n",
    "    MAEe.append(MAE(y_test, preds))\n",
    "    RMSEe.append(np.sqrt(MSE(y_test, preds)))\n",
    "print(\"Mean R squared\")\n",
    "print(\"%.3f\" % np.mean(r_squ), \"±\",  \"%.3f\" % np.std(r_squ))\n",
    "print(\"Mean MAE\")\n",
    "print(\"%.3f\" % np.mean(MAEe), \"±\",  \"%.3f\" % np.std(MAEe))\n",
    "print(\"Mean RMSE\")\n",
    "print(\"%.3f\" % np.mean(RMSEe), \"±\",  \"%.3f\" % np.std(RMSEe))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state = 2276)\n",
    "feat_cols = []\n",
    "# Testing FFS\n",
    "# Build Regressor to use in feature selection\n",
    "reg = LinearRegression()\n",
    "# Build step forward feature selection\n",
    "sfs1 = sfs(reg,\n",
    "           k_features = 2, # choisir après constatation\n",
    "           forward = True,\n",
    "           floating = False,\n",
    "           verbose = 2,\n",
    "           scoring = 'r2',\n",
    "           cv = 5,)\n",
    "\n",
    "# Perform SFFS\n",
    "sfs1 = sfs1.fit(X_train, y_train)\n",
    "# Which features?\n",
    "feat_cols = list(sfs1.k_feature_idx_)\n",
    "print(feat_cols)\n",
    "# Build full model with selected features\n",
    "reg.fit(X_train[:, feat_cols], y_train)\n",
    "y_test_pred = reg.predict(X_test[:, feat_cols])\n",
    "print('Testing R² on selected features: %.3f' % r2_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_squ = []\n",
    "MAEe = []\n",
    "RMSEe = []\n",
    "\n",
    "regressor = LinearRegression()\n",
    "for i in randomlist:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state = i)\n",
    "    regressor.fit(X_train[:, feat_cols], y_train)\n",
    "    preds = regressor.predict(X_test[:, feat_cols])\n",
    "    r_squ.append(r2_score(y_test, preds))\n",
    "    MAEe.append(MAE(y_test, preds))\n",
    "    RMSEe.append(np.sqrt(MSE(y_test, preds)))\n",
    "print(\"Mean R squared\")\n",
    "print(\"%.3f\" % np.mean(r_squ), \"+\",  \"%.3f\" % np.std(r_squ))\n",
    "print(\"Mean MAE\")\n",
    "print(\"%.3f\" % np.mean(MAEe), \"+\",  \"%.3f\" % np.std(MAEe))\n",
    "print(\"Mean RMSE\")\n",
    "print(\"%.3f\" % np.mean(RMSEe), \"+\",  \"%.3f\" % np.std(RMSEe))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state = 2276)\n",
    "feat_cols = []\n",
    "# Testing FFS\n",
    "# Build Regressor to use in feature selection\n",
    "reg = RandomForestRegressor()\n",
    "# Build step forward feature selection\n",
    "sfs1 = sfs(reg,\n",
    "           k_features = 10, # choisir après constatation\n",
    "           forward = True,\n",
    "           floating = False,\n",
    "           verbose = 2,\n",
    "           scoring = 'r2',\n",
    "           cv = 5,)\n",
    "\n",
    "# Perform SFFS\n",
    "sfs1 = sfs1.fit(X_train, y_train)\n",
    "# Which features?\n",
    "feat_cols = list(sfs1.k_feature_idx_)\n",
    "print(feat_cols)\n",
    "# Build full model with selected features\n",
    "reg.fit(X_train[:, feat_cols], y_train)\n",
    "y_test_pred = reg.predict(X_test[:, feat_cols])\n",
    "print('Testing R² on selected features: %.3f' % r2_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_squ = []\n",
    "MAEe = []\n",
    "RMSEe = []\n",
    "\n",
    "regressor = RandomForestRegressor()\n",
    "for i in randomlist:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state = i)\n",
    "    regressor.fit(X_train[:, feat_cols], y_train)\n",
    "    preds = regressor.predict(X_test[:, feat_cols])\n",
    "    r_squ.append(r2_score(y_test, preds))\n",
    "    MAEe.append(MAE(y_test, preds))\n",
    "    RMSEe.append(np.sqrt(MSE(y_test, preds)))\n",
    "print(\"Mean R squared\")\n",
    "print(\"%.3f\" % np.mean(r_squ), \"+\",  \"%.3f\" % np.std(r_squ))\n",
    "print(\"Mean MAE\")\n",
    "print(\"%.3f\" % np.mean(MAEe), \"+\",  \"%.3f\" % np.std(MAEe))\n",
    "print(\"Mean RMSE\")\n",
    "print(\"%.3f\" % np.mean(RMSEe), \"+\",  \"%.3f\" % np.std(RMSEe))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state = 2276)\n",
    "feat_cols = []\n",
    "# Testing FFS\n",
    "# Build Regressor to use in feature selection\n",
    "reg = XGBRegressor()\n",
    "# Build step forward feature selection\n",
    "sfs1 = sfs(reg,\n",
    "           k_features = 15, # choisir après constatation \n",
    "           forward = True,\n",
    "           floating = False,\n",
    "           verbose = 2,\n",
    "           scoring = 'r2',\n",
    "           cv = 5,)\n",
    "\n",
    "# Perform SFFS\n",
    "sfs1 = sfs1.fit(X_train, y_train)\n",
    "# Which features?\n",
    "feat_cols = list(sfs1.k_feature_idx_)\n",
    "print(feat_cols)\n",
    "# Build full model with selected features\n",
    "reg.fit(X_train[:, feat_cols], y_train)\n",
    "y_test_pred = reg.predict(X_test[:, feat_cols])\n",
    "print('Testing R² on selected features: %.3f' % r2_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_squ = []\n",
    "MAEe = []\n",
    "RMSEe = []\n",
    "\n",
    "regressor = XGBRegressor()\n",
    "for i in randomlist:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state = i)\n",
    "    regressor.fit(X_train[:, feat_cols], y_train)\n",
    "    preds = regressor.predict(X_test[:, feat_cols])\n",
    "    r_squ.append(r2_score(y_test, preds))\n",
    "    MAEe.append(MAE(y_test, preds))\n",
    "    RMSEe.append(np.sqrt(MSE(y_test, preds)))\n",
    "print(\"Mean R squared\")\n",
    "print(\"%.3f\" % np.mean(r_squ), \"+\",  \"%.3f\" % np.std(r_squ))\n",
    "print(\"Mean MAE\")\n",
    "print(\"%.3f\" % np.mean(MAEe), \"+\",  \"%.3f\" % np.std(MAEe))\n",
    "print(\"Mean RMSE\")\n",
    "print(\"%.3f\" % np.mean(RMSEe), \"+\",  \"%.3f\" % np.std(RMSEe))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LGBMRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state = 2276)\n",
    "feat_cols = []\n",
    "# Testing FFS\n",
    "# Build Regressor to use in feature selection\n",
    "reg = LGBMRegressor()\n",
    "# Build step forward feature selection\n",
    "sfs1 = sfs(reg,\n",
    "           k_features = 10, # choisir après constatation\n",
    "           forward = True,\n",
    "           floating = False,\n",
    "           verbose = 2,\n",
    "           scoring = 'r2',\n",
    "           cv = 5,)\n",
    "\n",
    "# Perform SFFS\n",
    "sfs1 = sfs1.fit(X_train, y_train)\n",
    "# Which features?\n",
    "feat_cols = list(sfs1.k_feature_idx_)\n",
    "print(feat_cols)\n",
    "# Build full model with selected features\n",
    "reg.fit(X_train[:, feat_cols], y_train)\n",
    "y_test_pred = reg.predict(X_test[:, feat_cols])\n",
    "print('Testing R² on selected features: %.3f' % r2_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_squ = []\n",
    "MAEe = []\n",
    "RMSEe = []\n",
    "\n",
    "regressor = LGBMRegressor()\n",
    "for i in randomlist:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state = i)\n",
    "    regressor.fit(X_train[:, feat_cols], y_train)\n",
    "    preds = regressor.predict(X_test[:, feat_cols])\n",
    "    r_squ.append(r2_score(y_test, preds))\n",
    "    MAEe.append(MAE(y_test, preds))\n",
    "    RMSEe.append(np.sqrt(MSE(y_test, preds)))\n",
    "print(\"Mean R squared\")\n",
    "print(\"%.3f\" % np.mean(r_squ), \"+\",  \"%.3f\" % np.std(r_squ))\n",
    "print(\"Mean MAE\")\n",
    "print(\"%.3f\" % np.mean(MAEe), \"+\",  \"%.3f\" % np.std(MAEe))\n",
    "print(\"Mean RMSE\")\n",
    "print(\"%.3f\" % np.mean(RMSEe), \"+\",  \"%.3f\" % np.std(RMSEe))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state = 2276)\n",
    "feat_cols = []\n",
    "# Testing FFS\n",
    "# Build Regressor to use in feature selection\n",
    "reg = CatBoostRegressor(silent = True)\n",
    "# Build step forward feature selection\n",
    "sfs1 = sfs(reg,\n",
    "           k_features = 13, # choisir après constatation\n",
    "           forward = True,\n",
    "           floating = False,\n",
    "           verbose = 2,\n",
    "           scoring = 'r2',\n",
    "           cv = 5,)\n",
    "\n",
    "# Perform SFFS\n",
    "sfs1 = sfs1.fit(X_train, y_train)\n",
    "# Which features?\n",
    "feat_cols = list(sfs1.k_feature_idx_)\n",
    "print(feat_cols)\n",
    "# Build full model with selected features\n",
    "reg.fit(X_train[:, feat_cols], y_train)\n",
    "y_test_pred = reg.predict(X_test[:, feat_cols])\n",
    "print('Testing R² on selected features: %.3f' % r2_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_squ = []\n",
    "MAEe = []\n",
    "RMSEe = []\n",
    "\n",
    "regressor = CatBoostRegressor(silent = True)\n",
    "for i in randomlist:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state = i)\n",
    "    regressor.fit(X_train[:, feat_cols], y_train)\n",
    "    preds = regressor.predict(X_test[:, feat_cols])\n",
    "    r_squ.append(r2_score(y_test, preds))\n",
    "    MAEe.append(MAE(y_test, preds))\n",
    "    RMSEe.append(np.sqrt(MSE(y_test, preds)))\n",
    "print(\"Mean R squared\")\n",
    "print(\"%.3f\" % np.mean(r_squ), \"+\",  \"%.3f\" % np.std(r_squ))\n",
    "print(\"Mean MAE\")\n",
    "print(\"%.3f\" % np.mean(MAEe), \"+\",  \"%.3f\" % np.std(MAEe))\n",
    "print(\"Mean RMSE\")\n",
    "print(\"%.3f\" % np.mean(RMSEe), \"+\",  \"%.3f\" % np.std(RMSEe))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features importance for the best regressor (CatBoostRegressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,16):\n",
    "    print(i,'\\t',imputed_df.columns[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data = imputed_df.drop(['crude'], axis = 1)\n",
    "my_data.columns\n",
    "\n",
    "reg = CatBoostRegressor(silent = True)\n",
    "reg.fit(X_train, y_train)\n",
    "sort = reg.feature_importances_.argsort()\n",
    "plt.barh(my_data.columns[sort], reg.feature_importances_[sort])\n",
    "plt.xlabel('Importance score', fontsize = 10)\n",
    "plt.ylabel('Feature', fontsize = 10, rotation = 90)\n",
    "plt.tight_layout()\n",
    "plt.savefig('importance.png', dpi = 300)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
